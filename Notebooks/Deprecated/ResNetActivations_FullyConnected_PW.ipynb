{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhCzcs9FCEfo"
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwS4AKEsCQ95"
   },
   "outputs": [],
   "source": [
    "def get_activations(img, base_model, activation = 1, print_ = False):\n",
    "    \"\"\"\n",
    "    Returns ReLUs of layer specified by parameter activation\n",
    "\n",
    "    :param img: np.array\n",
    "    :param base_model: Keras Model\n",
    "    :param activation_: int\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        img = np.array(img)\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    img = preprocess_input(img)\n",
    "    if print_: print(\"Shape of input:\", img.shape)\n",
    "    \n",
    "    model = Model(inputs=base_model.input,\n",
    "                  outputs=base_model.get_layer('activation_' + str(activation)).output)\n",
    "\n",
    "    activation = model.predict(img)\n",
    "    if print_: print(\"Shape of output:\", activation.shape)\n",
    "    \n",
    "    return activation\n",
    "  \n",
    "def remove_specific_label(X, y, label = 1):\n",
    "    not_label = y != label\n",
    "    return X[not_label], y[not_label]\n",
    "  \n",
    "def intialize_train(X_train, y_train, X_val, y_val, params):\n",
    "    \n",
    "    dim = params['dim']\n",
    "    neurons = params.pop('neurons', 512)\n",
    "    batch_size = params.pop('batch_size', 20)\n",
    "    epochs = params.pop('epochs', 20)\n",
    "    learning_rate = params.pop('lr', 2e-5)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(neurons, activation='relu', input_dim= dim[1] * dim[2] * dim[3]))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val))\n",
    "    \n",
    "    return history, model\n",
    "  \n",
    "def get_indices_of_wrong_classified_images(X, y, test_indices, model):\n",
    "    test_idx_wrong_classified = model.predict_classes(X).flatten() != y\n",
    "    img_wrong_classified = test_indices[test_idx_wrong_classified]\n",
    "    return img_wrong_classified\n",
    "\n",
    "  \n",
    "  \n",
    "import pickle\n",
    "\n",
    "def save_obj(obj, fullpath):\n",
    "    with open(fullpath + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(fullpath):\n",
    "    with open(fullpath + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "      \n",
    "      \n",
    "def save_keras_model(model, path, fold, res):\n",
    "\n",
    "    fullpath = os.path.join(path, 'model' + '_res' + str(res) + '_fold' + str(fold))\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(fullpath + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(fullpath + \".h5\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfMk5mAr3pS2"
   },
   "source": [
    "# RestNetActivations and Fully Connected layers\n",
    "\n",
    "IDEAS:\n",
    "* data augmentation\n",
    "* load images on batches (generator)\n",
    "* variable architecture for different resolutions (layers, epochs, etc)\n",
    "* show example images for every category and every label\n",
    "* show images on which the algorithm fails\n",
    "* what happens with the ResNet architecture for very small images?\n",
    "* cross validation accuracy and std\n",
    "* have more images, let's have on the order of 2000 images\n",
    "* use the label 1 images as test set\n",
    "* calculate activations and then train networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5051,
     "status": "ok",
     "timestamp": 1558795929906,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "xXxWhikiQvEB",
    "outputId": "20519c23-e1e7-45a3-f4a4-837b249ebe7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.6/dist-packages (0.10.2)\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCw0S6LyRDk7"
   },
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/qubvel/classification_models.git\n",
    "# potentially with smaller pretrained ResNet architectures\n",
    "# from classification_models.resnet import ResNet18, ResNet34, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WF0hLwdjXRHJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4338,
     "status": "ok",
     "timestamp": 1558795929913,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "p1tyKB5U3oTA",
    "outputId": "c706ceae-8b9d-4a1c-a48a-b49b3bce6d56"
   },
   "outputs": [],
   "source": [
    "try: # if running on COLAB\n",
    "    \n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH = '/content/drive/My Drive/Colab/MasterThesis/'\n",
    "    PATH_IMG = \"/content/drive/My Drive/MFP - Satellogic/images/\"\n",
    "    \n",
    "    # confirm GPU is available\n",
    "    #device_name = tf.test.gpu_device_name()\n",
    "    #if device_name != '/device:GPU:0':\n",
    "    #    raise SystemError('GPU device not found')\n",
    "\n",
    "except:\n",
    "    from dotenv import load_dotenv\n",
    "    sys.path.append(\"../Library/\")\n",
    "    import image_manipulation as ima\n",
    "    PATH = os.path.join(os.getenv('GDRIVE_FOLDER'), 'Colab/MasterThesis')\n",
    "    PATH_IMG = os.path.join(os.getenv('GDRIVE_FOLDER'), 'MFP - Satellogic/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4142,
     "status": "ok",
     "timestamp": 1558795929914,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "kVEXLcAI752R",
    "outputId": "36383a87-b0af-45c7-c527-997fb2625780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders content:\n",
      "PATH:\t\t ['.DS_Store', 'Icon\\r', 'Library', 'Models', 'Results_0.3m_excl_label1', '.env', 'Data', 'Notebooks']\n",
      "PATH DATA:\t ['result_res2.7.csv', 'result_res2.4.csv', 'result_res0.6.csv', 'X_activations_res0.3.npy', 'result_res4.2.csv', 'result_res2.1.csv', 'X_act_res1.8.npy', '.DS_Store', 'Icon\\r', 'X_act_res3.9.npy', 'result_res4.5.csv', 'X_act_res4.8.npy', 'result_res1.5.csv', 'result_res3.6.csv', 'result_res3.3.csv', 'result_res3.0.csv', 'result_res1.2.csv', 'X_act_res0.9.npy', 'X_act_res2.7.npy', 'y_images_res0.3.npy', 'X_act_res2.4.npy', 'X_act_res0.6.npy', 'X_act_res4.2.npy', 'X_act_res2.1.npy', 'result_res1.8.csv', 'X_images_res0.3.npy', 'X_act_res4.5.npy', 'result_res3.9.csv', 'result_res4.8.csv', 'X_act_res3.6.npy', 'X_act_res1.5.npy', 'X_act_res3.3.npy', 'X_act_res3.0.npy', 'result_res0.9.csv', 'X_act_res1.2.npy', '1m']\n",
      "PATH LIBRARY:\t ['image_download.py', 'deep_learning.py', '.DS_Store', 'Icon\\r', 'generate_dataset.py', 'IO.py', '__init__.py', '__pycache__', 'machine_learning.py', 'db_connection.py', 'image_manipulation.py', 'coordinates.py']\n",
      "PATH MODELS:\t ['Icon\\r', 'ER']\n",
      "PATH NOTEBOOKS:\t ['ResNetActivations_FullyConnected_ER.ipynb', '.DS_Store', 'ResNetActivations_FullyConnected.ipynb', 'Icon\\r', 'img', '.ipynb_checkpoints', 'ResNetActivations_FullyConnected_ER_bckp.ipynb', 'ResNetActivations_FullyConnected_ER_1m.ipynb', 'ResNetActivations_FullyConnected_PW.ipynb']\n",
      "PATH IMAGES:\t ['.DS_Store', 'Icon\\r', 'usgs_512_res1m', 'labels', 'raw_images_usgs_1m', 'gmaps', 'raw_images_usgs_0.3m', 'usgs_512_res0.3m']\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = os.path.join(PATH, 'Data/')\n",
    "PATH_LIB = os.path.join(PATH, 'Library/')\n",
    "PATH_MOD = os.path.join(PATH, 'Models/')\n",
    "PATH_NOTE = os.path.join(PATH, 'Notebooks/')\n",
    "sys.path.append(PATH_LIB)\n",
    "\n",
    "print(\"Folders content:\")\n",
    "print(\"PATH:\\t\\t\", os.listdir(PATH))\n",
    "print(\"PATH DATA:\\t\", os.listdir(PATH_DATA))\n",
    "print(\"PATH LIBRARY:\\t\", os.listdir(PATH_LIB))\n",
    "print(\"PATH MODELS:\\t\", os.listdir(PATH_MOD))\n",
    "print(\"PATH NOTEBOOKS:\\t\", os.listdir(PATH_NOTE))\n",
    "print(\"PATH IMAGES:\\t\", os.listdir(PATH_IMG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3828,
     "status": "ok",
     "timestamp": 1558795929915,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "do1lu4du9Gtf",
    "outputId": "d657d29e-dfb1-4657-e408-fcb8244de5e7"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import deep_learning as dl\n",
    "import image_manipulation as ima\n",
    "import machine_learning as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xyYeD4VLBem"
   },
   "outputs": [],
   "source": [
    "def print_time(string=''):\n",
    "    print('', str(datetime.datetime.today())[:22], string)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwnY1El3IysC"
   },
   "source": [
    "## Train complete network from source images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xc2gXgS0JsQh"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qElQpaKa6QTD"
   },
   "outputs": [],
   "source": [
    "X_name = 'X_images_res0.3.npy'\n",
    "y_name = 'y_images_res0.3.npy'\n",
    "\n",
    "X_base, y = np.load(os.path.join(PATH_DATA, X_name)), np.load(os.path.join(PATH_DATA, y_name), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKzemCPs7qKf"
   },
   "source": [
    "### Resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1558795932312,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "iQxX6OCS6Udz",
    "outputId": "84748352-82c8-438b-c5b3-4a3df76863e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes dictionary:\n",
      " {0.3: (512, 512), 0.6: (256, 256), 0.9: (171, 171), 1.2: (128, 128), 1.5: (102, 102), 1.8: (85, 85), 2.1: (73, 73), 2.4: (64, 64), 2.7: (57, 57), 3.0: (51, 51), 3.3: (47, 47), 3.6: (43, 43), 3.9: (39, 39), 4.2: (37, 37), 4.5: (34, 34), 4.8: (32, 32)}\n"
     ]
    }
   ],
   "source": [
    "base_res = 0.3\n",
    "base_size = 512\n",
    "N_RES = 17\n",
    "\n",
    "sizes = {base_res: (base_size, base_size)}\n",
    "for factor in range(2, N_RES):\n",
    "    res = round(base_res * factor,1)\n",
    "    size = round(base_size/factor)\n",
    "    sizes[res] = (size, size)\n",
    "print(\"Sizes dictionary:\\n\", sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "il1gfOFxSslJ"
   },
   "source": [
    "### List of all resolutions (including base):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3804,
     "status": "ok",
     "timestamp": 1558795932313,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "zNXzypwrRr-t",
    "outputId": "5bd33cd4-7bf6-48e4-f66a-89817f62d3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3.0, 3.3, 3.6, 3.9, 4.2, 4.5, 4.8]\n"
     ]
    }
   ],
   "source": [
    "resolutions = [res for res in sizes]\n",
    "resolutions.sort()\n",
    "print(resolutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jH44VeLtSYe3"
   },
   "source": [
    "### Load base NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9Fl20x8TCT8"
   },
   "source": [
    "Load ResNet and set all layers to `trainable = False` and list *activation* layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14755,
     "status": "ok",
     "timestamp": 1558795944204,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "avX0yPxomT1w",
    "outputId": "c8562f3c-7d98-4581-a243-1919bbd724ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/peterweber/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterweber/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the md5 file hash does not match the original value of a268eb855778b3df3c7506639542a6af so we will re-download the data.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 108s 1us/step\n",
      "['activation_1', 'activation_2', 'activation_3', 'activation_4', 'activation_5', 'activation_6', 'activation_7', 'activation_8', 'activation_9', 'activation_10', 'activation_11', 'activation_12', 'activation_13', 'activation_14', 'activation_15', 'activation_16', 'activation_17', 'activation_18', 'activation_19', 'activation_20', 'activation_21', 'activation_22', 'activation_23', 'activation_24', 'activation_25', 'activation_26', 'activation_27', 'activation_28', 'activation_29', 'activation_30', 'activation_31', 'activation_32', 'activation_33', 'activation_34', 'activation_35', 'activation_36', 'activation_37', 'activation_38', 'activation_39', 'activation_40', 'activation_41', 'activation_42', 'activation_43', 'activation_44', 'activation_45', 'activation_46', 'activation_47', 'activation_48', 'activation_49']\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet',\n",
    "                      include_top=False)\n",
    "\n",
    "activation_layers = []\n",
    "for l in base_model.layers:\n",
    "    l.trainable = False\n",
    "    if \"activation\" in l.name or \"relu\" in l.name:\n",
    "        activation_layers.append(l.name)\n",
    "print(activation_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKa9-ZASSi3M"
   },
   "outputs": [],
   "source": [
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dVfN-yYltDt"
   },
   "source": [
    "# Run DL pipeline for all resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141576
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5303301,
     "status": "ok",
     "timestamp": 1558802120219,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "vEb5bPOclrfx",
    "outputId": "c34c4de1-908b-45d5-d4c5-abbcd0469a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Getting Activations for resolution 0.3 ---\n",
      "\n",
      "\n",
      " ---- Processing fold 0 at resolution 0.3 --- \n",
      "\n",
      " 2019-05-27 13:51:22.92 training...\n",
      "Train on 1770 samples, validate on 254 samples\n",
      "Epoch 1/30\n",
      "1050/1770 [================>.............] - ETA: 46s - loss: 8.0360 - acc: 0.4762"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12f732445a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintialize_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c81c6fe4eea4>\u001b[0m in \u001b[0;36mintialize_train\u001b[0;34m(X_train, y_train, X_val, y_val, params)\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         validation_data=(X_val, y_val))\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2965\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2967\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda2/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAVE_RESULT = True\n",
    "SAVE_MODEL = True\n",
    "RESOLUTIONS = [resolutions[0]]\n",
    "\n",
    "\n",
    "N_images = X_base.shape[0]\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kFold = StratifiedKFold(n_splits=8, random_state = 42)\n",
    "batch_size = 50\n",
    "results = []\n",
    "\n",
    "N_ACTIVATIONS = len(activation_layers)\n",
    "act_layer = activation_layers[N_ACTIVATIONS-1]\n",
    "\n",
    "for res in RESOLUTIONS:\n",
    " \n",
    "\n",
    "    ## Degrading\n",
    "    X = np.array([ima.degrade_image(X_base[i], sizes[res]) for i in range(N_images)])\n",
    "\n",
    "    ## Activations and Preprocessing\n",
    "    print(\"\\n--- Getting Activations for resolution\", res, \"---\\n\")\n",
    "    \n",
    "    ## Load Activations from disk, if exist\n",
    "    path_act = os.path.join(PATH_DATA, 'X_act_res' + str(res) + '.npy')\n",
    "    if os.path.exists(path_act):\n",
    "        print(\"Loading activations from disk...\")\n",
    "        X_act = np.load(path_act)\n",
    "    else:\n",
    "        X_act = get_activations(X[0], base_model, int(activation_layers[-1].split(\"_\")[-1]))\n",
    "        for i in range(1, X.shape[0], batch_size):\n",
    "            X_act = np.r_[X_act, get_activations(X[i:i+batch_size], base_model, int(activation_layers[-1].split(\"_\")[-1]))]\n",
    "        np.save(path_act, X_act)\n",
    "    X_act = preprocess_input(X_act)\n",
    "\n",
    "    ## Initialize parameters for CV\n",
    "    params = {}\n",
    "    fold = 0\n",
    "    result_per_res = []\n",
    "    \n",
    "    ## Training with CV\n",
    "    for train, val in kFold.split(X_act, y):\n",
    "        \n",
    "        print(\"\\n ---- Processing fold\", fold, \"at resolution\", res, \"--- \\n\")\n",
    "        \n",
    "        dim = X_act.shape\n",
    "        X_train = np.reshape(X_act[train], (X_act[train].shape[0], dim[1] * dim[2] * dim[3]))\n",
    "        X_val = np.reshape(X_act[val], (X_act[val].shape[0], dim[1] * dim[2] * dim[3]))\n",
    "        y_train, y_val = y[train], y[val]\n",
    "\n",
    "        params['dim'] = dim\n",
    "        params['batch_size'] = batch_size\n",
    "        params['epochs'] = 30\n",
    "        params['neurons'] = 256\n",
    "        \n",
    "        print_time(\"training...\")\n",
    "        history, model = intialize_train(X_train, y_train, X_val, y_val, params)\n",
    "        del X_train, y_train\n",
    "\n",
    "        print_time(\"evaluating...\")\n",
    "        loss, acc = model.evaluate(X_val, y_val)\n",
    "        print('Accuracy:', acc)\n",
    "        \n",
    "        # Get indices of wrongly classified images\n",
    "        img_wrong_classified = get_indices_of_wrong_classified_images(X_val, y_val, val, model)\n",
    "                \n",
    "        if SAVE_MODEL: save_keras_model(model, PATH_DATA, fold, res)\n",
    "        \n",
    "        result = {\n",
    "            \"wrong_class\": img_wrong_classified.tolist(),\n",
    "            \"resolution\": res,\n",
    "            \"accuracy\": acc,\n",
    "            \"loss\": loss,\n",
    "            \"history\": history,\n",
    "            \"fold\": fold\n",
    "        }\n",
    "        del X_val, y_val, model, history\n",
    "        \n",
    "        result_per_res.append(result) \n",
    "        fold += 1\n",
    "     \n",
    "    if SAVE_RESULT: pd.DataFrame(result_per_res).to_csv(os.path.join(PATH_DATA, \"result_res\" + str(res) + \".csv\"), index=False)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "del X\n",
    "del X_act\n",
    "\n",
    "print_time(\"DONE! \\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVSImK72wGdl"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBOQn8iSSvmB"
   },
   "outputs": [],
   "source": [
    "res = 0.6\n",
    "df_results = pd.read_csv(os.path.join(PATH_DATA, \"result_res\" + str(res) + \".csv\"))\n",
    "for res in resolutions[2:]:\n",
    "  df_results = df_results.append(pd.read_csv(os.path.join(PATH_DATA, \"result_res\" + str(res) + \".csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1813,
     "status": "ok",
     "timestamp": 1558727264996,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "Lh1abSMYvH_6",
    "outputId": "922fb1e6-56ef-4aad-e03b-5a1262851ca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.956020</td>\n",
       "      <td>0.015460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.945164</td>\n",
       "      <td>0.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.939713</td>\n",
       "      <td>0.016617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.931324</td>\n",
       "      <td>0.014320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>0.933287</td>\n",
       "      <td>0.015620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.918482</td>\n",
       "      <td>0.015055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0.919449</td>\n",
       "      <td>0.013963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0.906605</td>\n",
       "      <td>0.021517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.902152</td>\n",
       "      <td>0.023152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0.901176</td>\n",
       "      <td>0.017748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0.891759</td>\n",
       "      <td>0.028647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.885830</td>\n",
       "      <td>0.027689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.2</td>\n",
       "      <td>0.896231</td>\n",
       "      <td>0.023187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.892276</td>\n",
       "      <td>0.022644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.8</td>\n",
       "      <td>0.876464</td>\n",
       "      <td>0.024623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  accuracy          \n",
       "                   mean       std\n",
       "0         0.6  0.956020  0.015460\n",
       "1         0.9  0.945164  0.009278\n",
       "2         1.2  0.939713  0.016617\n",
       "3         1.5  0.931324  0.014320\n",
       "4         1.8  0.933287  0.015620\n",
       "5         2.1  0.918482  0.015055\n",
       "6         2.4  0.919449  0.013963\n",
       "7         2.7  0.906605  0.021517\n",
       "8         3.0  0.902152  0.023152\n",
       "9         3.3  0.901176  0.017748\n",
       "10        3.6  0.891759  0.028647\n",
       "11        3.9  0.885830  0.027689\n",
       "12        4.2  0.896231  0.023187\n",
       "13        4.5  0.892276  0.022644\n",
       "14        4.8  0.876464  0.024623"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = df_results.groupby(['resolution'], as_index=False).agg(\n",
    "                          {'accuracy':['mean','std']})\n",
    "\n",
    "grouped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4tEvR_OwIy6"
   },
   "source": [
    "Accuracy for each resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1639,
     "status": "ok",
     "timestamp": 1558727300499,
     "user": {
      "displayName": "Peter Weber",
      "photoUrl": "",
      "userId": "04417633848908167666"
     },
     "user_tz": -120
    },
    "id": "TL-udABMqG_w",
    "outputId": "cac6a2f4-3a8e-4ef2-9cca-c09d5319ef35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAHwCAYAAACYMcj+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiSpAIO2JEmSVIBBW5IkSSrg/wf1dP4ZtEGEsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12,8)\n",
    "\n",
    "ax.errorbar(grouped_results[\"resolution\"], \n",
    "            grouped_results.accuracy[\"mean\"], \n",
    "            grouped_results.accuracy[\"std\"],\n",
    "            linestyle='None', marker='x'\n",
    "           )  \n",
    "ax.set(\n",
    "    xlabel=\"Resolution\",\n",
    "    ylabel=\"Accuracy\",\n",
    "    title = \"Classification accuracy vs resolution\"\n",
    ")\n",
    "ax.grid()\n",
    "#ax.legend()\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(PATH_NOTE + 'img/acc_vs_res_' + str(datetime.datetime.today())[:16].replace(\":\",\".\") + '_.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlajmHkIZ0EB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNetActivations_FullyConnected_PW.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
